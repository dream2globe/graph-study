{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0f5c937a",
   "metadata": {},
   "source": [
    "# Building a Regression Model in PyTorch\n",
    "- Updated 2023.04.21\n",
    "- Written by shyeon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c1a60f",
   "metadata": {},
   "source": [
    "## Initialize setting"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b53ee5e6",
   "metadata": {},
   "source": [
    "- Project path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa7bf72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "curr_path = Path().absolute()\n",
    "os.chdir(curr_path.parent)  # change working directory to parent path"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "94f468cf",
   "metadata": {},
   "source": [
    "- Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00351e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.models.rank import radiorank\n",
    "from src.utils.graph import build_nx_graph\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5edf809b",
   "metadata": {},
   "source": [
    "- Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e690f0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 42"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1384fd6a",
   "metadata": {},
   "source": [
    "\n",
    "## Data Loader"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2ffc2e2f",
   "metadata": {},
   "source": [
    "- Prepare train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31d19859",
   "metadata": {},
   "outputs": [],
   "source": [
    "value_df = pd.read_pickle(\"data/processed/values.pickle\")\n",
    "\n",
    "test_items = value_df.columns.tolist()\n",
    "item_2_idx = {v: k for k, v in enumerate(test_items)}\n",
    "idx_2_item = {k: v for k, v in enumerate(test_items)}\n",
    "\n",
    "train_df, test_df = train_test_split(value_df, test_size=0.5, random_state=random_seed, shuffle=False)\n",
    "scaler = StandardScaler().fit(train_df)\n",
    "# scaled_train = pd.DataFrame(scaler.transform(train), columns=train.columns)\n",
    "# scaled_test = pd.DataFrame(scaler.transform(test), columns=test.columns)\n",
    "scaled_train_df = pd.DataFrame(scaler.transform(train_df))\n",
    "scaled_test_df = pd.DataFrame(scaler.transform(test_df))\n",
    "titles = scaled_train_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03a5fff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RfFinalTestDataset(Dataset):\n",
    "    def __init__(self, df:pd.DataFrame, input_nm:list, label_nm:list) -> None:\n",
    "        self.df = df\n",
    "        self.input_nm = input_nm\n",
    "        self.label_nm = label_nm\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.df.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx:int) -> tuple[np.array, np.array] :\n",
    "        inputs = self.df.loc[idx, self.input_nm].values\n",
    "        labels = self.df.loc[idx, self.label_nm].values\n",
    "        return inputs, labels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6a3dfd11",
   "metadata": {},
   "source": [
    "## Build a prediction model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43ae57d",
   "metadata": {},
   "source": [
    "- Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a17a5e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ac37f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, in_num, out_num):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        gap_by_step = int((in_num - out_num) / 2) # the num of hidden layer + 1\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(in_num, in_num-gap_by_step),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_num-gap_by_step, in_num-gap_by_step*2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_num-gap_by_step*2, out_num),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d561ca6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corr = scaled_train_df.corr()\n",
    "G = build_nx_graph(train_corr, titles)\n",
    "\n",
    "selected_nodes = radiorank(G, 0.1, \"value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "506ffce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=40, out_features=33, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=33, out_features=26, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=26, out_features=26, bias=True)\n",
      "    (5): ReLU()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "train_dataset = RfFinalTestDataset(scaled_train_df, selected_nodes[:40], selected_nodes[40:])\n",
    "test_dataset = RfFinalTestDataset(scaled_test_df, selected_nodes[:40], selected_nodes[40:])\n",
    "\n",
    "model = NeuralNetwork(len(selected_nodes[:40]), len(selected_nodes[40:]))\n",
    "model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23622241",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "batch_size = 1000\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "413056b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cdc904d8",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'DataLoader' object is not an iterator",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mnext\u001b[39;49m(train_dataloader)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'DataLoader' object is not an iterator"
     ]
    }
   ],
   "source": [
    "next(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1456b850",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_stats = {\n",
    "    \"train\": [],\n",
    "    \"val\": []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "24f929a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin training.\n",
      "torch.Size([1000, 40]) torch.Size([1000, 26])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 must have the same dtype",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m X_train_batch, y_train_batch \u001b[39m=\u001b[39m X_train_batch\u001b[39m.\u001b[39mto(device), y_train_batch\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     11\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> 12\u001b[0m y_train_pred \u001b[39m=\u001b[39m model(X_train_batch)\n\u001b[1;32m     13\u001b[0m train_loss \u001b[39m=\u001b[39m loss_fn(y_train_pred, y_train_batch\u001b[39m.\u001b[39munsqueeze(\u001b[39m1\u001b[39m))\n\u001b[1;32m     14\u001b[0m train_loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.3/envs/graph/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[7], line 15\u001b[0m, in \u001b[0;36mNeuralNetwork.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> 15\u001b[0m     logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlinear_relu_stack(x)\n\u001b[1;32m     16\u001b[0m     \u001b[39mreturn\u001b[39;00m logits\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.3/envs/graph/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.3/envs/graph/lib/python3.11/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.3/envs/graph/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.3/envs/graph/lib/python3.11/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 must have the same dtype"
     ]
    }
   ],
   "source": [
    "print(\"Begin training.\")\n",
    "with tqdm(range(epochs), unit=\"batch\", mininterval=0, disable=True) as bar:    \n",
    "    for epoch in bar:\n",
    "        bar.set_description(f\"Epoch {epoch}\")        \n",
    "        # TRAINING\n",
    "        train_epoch_loss = 0\n",
    "        model.train()\n",
    "        for X_train_batch, y_train_batch in train_dataloader:\n",
    "            print(X_train_batch.shape, y_train_batch.shape)\n",
    "            X_train_batch, y_train_batch = X_train_batch.to(device), y_train_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            y_train_pred = model(X_train_batch)\n",
    "            train_loss = loss_fn(y_train_pred, y_train_batch.unsqueeze(1))\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "            train_epoch_loss += train_loss.item()\n",
    "            \n",
    "        # VALIDATION    \n",
    "        with torch.no_grad():\n",
    "            val_epoch_loss = 0\n",
    "            model.eval()\n",
    "            for X_val_batch, y_val_batch in test_dataloader:\n",
    "                X_val_batch, y_val_batch = X_val_batch.to(device), y_val_batch.to(device)\n",
    "                y_val_pred = model(X_val_batch)\n",
    "                val_loss = loss_fn(y_val_pred, y_val_batch.unsqueeze(1))\n",
    "                \n",
    "                val_epoch_loss += val_loss.item()\n",
    "        loss_stats['train'].append(train_epoch_loss/len(train_dataloader))\n",
    "        loss_stats['val'].append(val_epoch_loss/len(test_dataloader))                              \n",
    "    \n",
    "    print(f'Epoch {e+0:03}: | Train Loss: {train_epoch_loss/len(train_dataloader):.5f} | Val Loss: {val_epoch_loss/len(test_dataloader):.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512f4cf0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "149b880323cb511abb378ca8a7f1ace7211f133ce014a578336d1234f1f242ee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
