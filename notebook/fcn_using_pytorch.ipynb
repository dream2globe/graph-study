{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0f5c937a",
   "metadata": {},
   "source": [
    "# Building a Regression Model in PyTorch\n",
    "- Updated 2023.04.21\n",
    "- Written by shyeon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c1a60f",
   "metadata": {},
   "source": [
    "## Initialize setting"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b53ee5e6",
   "metadata": {},
   "source": [
    "- Project path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa7bf72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "curr_path = Path().absolute()\n",
    "os.chdir(curr_path.parent)  # change working directory to parent path"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "94f468cf",
   "metadata": {},
   "source": [
    "- Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00351e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from src.models.rank import radiorank\n",
    "from src.utils.graph import build_nx_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5edf809b",
   "metadata": {},
   "source": [
    "- Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e690f0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 42"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1384fd6a",
   "metadata": {},
   "source": [
    "\n",
    "## Data Loader"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2ffc2e2f",
   "metadata": {},
   "source": [
    "- Prepare train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31d19859",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas.core.indexes.numeric'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mdata/processed/values.pickle\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m----> 2\u001b[0m     value_df \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39;49mload(f)\n\u001b[1;32m      4\u001b[0m test_items \u001b[39m=\u001b[39m value_df\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mtolist()\n\u001b[1;32m      5\u001b[0m item_2_idx \u001b[39m=\u001b[39m {v: k \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(test_items)}\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas.core.indexes.numeric'"
     ]
    }
   ],
   "source": [
    "value_df = pd.read_pickle(\"data/processed/values.pickle\")\n",
    "\n",
    "test_items = value_df.columns.tolist()\n",
    "item_2_idx = {v: k for k, v in enumerate(test_items)}\n",
    "idx_2_item = {k: v for k, v in enumerate(test_items)}\n",
    "\n",
    "train_df, test_df = train_test_split(value_df, test_size=0.5, random_state=random_seed, shuffle=False)\n",
    "scaler = StandardScaler().fit(train_df)\n",
    "# scaled_train = pd.DataFrame(scaler.transform(train), columns=train.columns)\n",
    "# scaled_test = pd.DataFrame(scaler.transform(test), columns=test.columns)\n",
    "scaled_train_df = pd.DataFrame(scaler.transform(train_df))\n",
    "scaled_test_df = pd.DataFrame(scaler.transform(test_df))\n",
    "titles = scaled_train_df.columns.tolist()\n",
    "\n",
    "scaled_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03a5fff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RfFinalTestDataset(Dataset):\n",
    "    def __init__(self, df:pd.DataFrame, input_nm:list, label_nm:list) -> None:\n",
    "        self.df = df\n",
    "        self.input_nm = input_nm\n",
    "        self.label_nm = label_nm\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.df.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx:int) -> tuple[np.array, np.array] :\n",
    "        inputs = self.df.loc[idx, self.input_nm].values\n",
    "        labels = self.df.loc[idx, self.label_nm].values\n",
    "        return inputs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4fa0150",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scaled_train_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_dataset \u001b[39m=\u001b[39m RfFinalTestDataset(scaled_train_df, titles[:\u001b[39m10\u001b[39m], titles[\u001b[39m10\u001b[39m:])\n\u001b[1;32m      2\u001b[0m test_dataset \u001b[39m=\u001b[39m RfFinalTestDataset(scaled_test_df, titles[:\u001b[39m10\u001b[39m], titles[\u001b[39m10\u001b[39m:])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'scaled_train_df' is not defined"
     ]
    }
   ],
   "source": [
    "train_dataset = RfFinalTestDataset(scaled_train_df, titles[:10], titles[10:])\n",
    "test_dataset = RfFinalTestDataset(scaled_test_df, titles[:10], titles[10:])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6a3dfd11",
   "metadata": {},
   "source": [
    "## Build a prediction model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43ae57d",
   "metadata": {},
   "source": [
    "- Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a17a5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac37f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, in_num, out_num):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        gap_by_step = int((in_num - out_num) / 2) # the num of hidden layer + 1\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(in_num, in_num-gap_by_step),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_num-gap_by_step, in_num-gap_by_step*2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_num-gap_by_step*2, out_num),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d561ca6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corr = scaled_train_df.corr()\n",
    "G = build_nx_graph(train_corr, titles)\n",
    "\n",
    "selected_nodes = radiorank(G, 0.1, \"value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506ffce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetwork(len(selected_nodes[:40]), len(selected_nodes[40:])).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bc776a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=100, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=100, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413056b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "learning_rate = 1e-3\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1456b850",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "149b880323cb511abb378ca8a7f1ace7211f133ce014a578336d1234f1f242ee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
